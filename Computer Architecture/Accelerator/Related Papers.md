# IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD)
## Volume 43
### NUMBER 10
1. **ARCTIC: Approximate Real-Time Computing in a Cache-Conscious Multicore Environment**
   - 作者: S. Saha, S. Chakraborty, S. Agarwal, M. Sjölander, and K.D. McDonald-Maier
   - 页码: 2944
   - 摘要: 该论文讨论了在一个缓存意识的多核环境中进行近似实时计算的方法，这可能与硬件加速和优化有关。

2. **GREEN: An Approximate SIMD/MIMD CGRA for Energy-Efficient Processing at the Edge**
   - 作者: Z. Ebrahimi and A. Kumar
   - 页码: 2874
   - 摘要: 该论文介绍了一种用于边缘设备能效处理的近似SIMD/MIMD CGRA（粗粒度可重构阵列），直接关联到硬件加速技术。

3. **FPGAs and Reconfigurable Systems** 类别下的几篇论文也涉及硬件加速：
   - **Hardware-Friendly 3-D CNN Acceleration With Balanced Kernel Group Sparsity**
     - 作者: M. Sun, K. Xu, X. Lin, Y. Hu, and B. Yin
     - 页码: 3027
   - **Unleashing Network/Accelerator Co-Exploration Potential on FPGAs: A Deeper Joint Search**
     - 作者: W. Lou, L. Gong, C. Wang, J. Qian, X. Wang, C. Li, and X. Zhou
     - 页码: 3041
   - **Cascade: An Application Pipelining Toolkit for Coarse-Grained Reconfigurable Arrays**
     - 作者: J. Melchert, Y. Mei, K. Koul, Q. Liu, M. Horowitz, and P. Raina
     - 页码: 3055
   - **The Road Not Taken: eFPGA Accelerators Utilized for SoC Security Auditing**
     - 作者: M.M.M. Rahman, S. Tarek, K.Z. Azar, M. Tehranipoor, and F. Farahmandi
     - 页码: 3068
   - **AutoAI2C: An Automated Hardware Generator for DNN Acceleration on Both FPGA and ASIC**
     - 作者: Y. Zhang, X. Zhang, P. Xu, Y. Zhao, C. Hao, D. Chen, and Y. Lin
     - 页码: 3143

### NUMBER 9

4. **FireFly v2: Advancing Hardware Support for High-Performance Spiking Neural Network With a Spatiotemporal FPGA Accelerator**
   - 作者：J.Li, G.Shen, D.Zhao, Q.Zhang, 和 Y.Zeng
   - 页码：2647
   - 简介：该文讨论了FireFly v2，一个针对高性能脉冲神经网络（SNN）的时空FPGA加速器，展示了在硬件层面对SNN的加速支持。

5. **SPADIX: A Highly Efficient Accelerator for Solving 3-D Partial Differential Equations**
   - 作者：J.Li 和 Y.Deng
   - 页码：2797
   - 简介：介绍了一个高效的加速器SPADIX，用于解决三维偏微分方程（PDEs），这可能涉及到硬件加速来优化计算密集型任务。

### NUMBER 8



1. **ReApprox-PIM: Reconfigurable Approximate Lookup-Table(LUT)-Based Processing-in-Memory(PIM) Machine Learning Accelerator**
   - 作者：S. Bavikadi, P.R. Sutradhar, M.A. Indovina, A. Ganguly, and S.M.P. Dinakarrao
   - 页码：2288
   - 内容概述：该研究设计了一种基于可重构近似查找表（LUT）的处理内存（PIM）机器学习加速器，通过处理内存的方式来实现硬件加速，适用于机器学习应用。

2. **APIM: An Antiferromagnetic MRAM-Based Processing-In-Memory System for Efficient Bit-Level Operations of Quantized Convolutional Neural Networks**
   - 作者：Y. Li, J. Wang, D. Zhu, J. Li, A. Du, X. Wang, Y. Zhang, and W. Zhao
   - 页码：2405
   - 内容概述：该研究提出了一种基于反铁磁MRAM的处理内存系统，用于量化卷积神经网络（CNN）的高效位级操作，旨在通过处理内存技术来加速CNN的计算。

3. **Compute-in-Memory-Based Neural Network Accelerators for Safety-Critical Systems: Worst-Case Scenarios and Protections**
   - 作者：Z. Yan, X.S. Hu, and Y. Shi
   - 页码：2452
   - 内容概述：该论文探讨了基于计算内存（CIM）的神经网络加速器在安全关键系统中的应用，包括最坏情况分析和保护措施，以提高加速性能和系统安全性。

4. **Mitigating Slow-to-Write Errors in Memristor-Mapped Graph Neural Networks Induced by Adversarial Attacks**
   - 作者：C.-Y. Chen, B.K. Joardar, J.R. Doppa, P.P. Pande, and K. Chakrabarty
   - 页码：2411
   - 内容概述：尽管此论文主要关注于缓解由对抗性攻击引起的忆阻器映射图神经网络中的慢写入错误，但它也探讨了忆阻器在硬件加速方面的应用，特别是在图神经网络中的实现。

5. **Parmesan: Efficient Partitioning and Mapping Flow for DNN Training on General Device Topology**
   - 作者：L. Liu, T. Liu, B. Jiang, and E.F.Y. Young
   - 页码：2426
   - 内容概述：该研究提出了一种有效的分区和映射流程，用于在通用设备拓扑上进行深度神经网络（DNN）的训练，这涉及到硬件加速策略的设计，以优化DNN训练的性能。

### NUMBER 7


1. **An ASIC Accelerator for QNN With Variable Precision and Tunable Energy Efficiency**
   - 作者：A. Wagle, G. Singh, S. Khatri, and S. Vrudhula
   - 起始页码：2057
   - 内容概要：介绍了一个用于量子神经网络（QNN）的ASIC加速器，该加速器支持可变精度和可调能效。

2. **GroupQ: Group-Wise Quantization With Multi-Objective Optimization for CNN Accelerators**
   - 作者：A. Jiang, L. Du, and Y. Du
   - 起始页码：2071
   - 内容概要：提出了一种针对CNN加速器的组级量化方法，该方法采用多目标优化。

3. **CIM2PQ: An Arraywise and Hardware-Friendly Mixed Precision Quantization Method for Analog Computing-In-Memory**
   - 作者：S. Sun, J. Bai, Z. Shi, W. Zhao, and W. Kang
   - 起始页码：2084
   - 内容概要：描述了一种针对模拟存内计算（CIM）的阵列级和硬件友好的混合精度量化方法。

4. **SUN: Dynamic Hybrid-Precision SRAM-Based CIM Accelerator With High Macro Utilization Using Structured Pruning Mixed-Precision Networks**
   - 作者：Y.-W. Chen, R.-H. Wang, Y.-H. Cheng, C.-C. Lu, M.-F. Chang, and K.-T. Tang
   - 起始页码：2163
   - 内容概要：介绍了一种基于SRAM的动态混合精度CIM加速器，通过使用结构化剪枝混合精度网络实现高宏利用率。

### NUMBER 6


1. **Analytical Die-to-Die 3-D Placement With Bistratal Wirelength Model and GPU Acceleration**
   - 作者：P. Liao, Y. Zhao, D. Guo, Y. Lin, and B. Yu
   - 摘要：这篇论文讨论了利用双层线长模型和GPU加速的三维芯片间放置分析。这涉及到硬件加速技术，特别是GPU在优化三维集成电路设计中的应用。

2. **CPSAA: Accelerating Sparse Attention Using Crossbar-Based Processing-In-Memory Architecture**
   - 作者：H. Li, H. Jin, L. Zheng, X. Liao, Y. Huang, C. Liu, J. Xu, Z. Duan, D. Chen, and C. Gui
   - 摘要：该研究提出了一个基于交叉开关的处理内存架构（CPSAA），用于加速稀疏注意力计算。这是一种利用特定硬件架构来加速机器学习模型中的关键操作的方法。

3. **An Energy-Efficient In-Memory Accelerator for Graph Construction and Updating**
   - 作者：M. Chen, C. Liu, S. Liang, L. He, Y. Wang, L. Zhang, H. Li, and X. Li
   - 摘要：该论文介绍了一种用于图构建和更新的内存内加速器，旨在提高能效。内存内计算是一种硬件加速技术，它通过减少数据移动来优化性能。

4. **Mobile Transformer Accelerator Exploiting Various Line Sparsity and Tile-Based Dynamic Quantization**
   - 作者：E. Kwon, J. Yoon, and S. Kang
   - 摘要：虽然这篇论文主要聚焦于移动Transformer加速器的设计，但它讨论了利用线路稀疏性和基于瓦片的动态量化来优化性能，这也可以视为一种硬件加速技术。

5. **U-SWIM: Universal Selective Write-Verify for Computing-in-Memory Neural Accelerators**
   - 作者：Z. Yan, X.S. Hu, and Y. Shi
   - 摘要：该研究提出了一个针对内存计算神经加速器的通用选择性写入验证机制（U-SWIM），这也是一种硬件加速技术，旨在提高内存计算的可靠性和效率。

6. **Xplace: An Extremely Fast and Extensible Placement Framework**
   - 作者：L. Liu, B. Fu, S. Lin, J. Liu, E.F.Y. Young, and M.D.F. Wong
   - 虽然这篇论文主要聚焦于布局框架，但它强调了“极其快速”的特点，这通常与高效的硬件加速实现相关。

### NUMBER 5


1. **PhGraph: A High-Performance ReRAM-Based Accelerator for Hypergraph Applications**
   - 作者：L. Zheng, A. Hu, Q. Wang, Y. Huang, H. Huang, P. Yao, S. Xiong, X. Liao, and H. Jin
   - 类别：Analog, Mixed-Signal, and RF Circuits
   - 摘要：这篇论文提出了一种基于ReRAM（电阻式随机存取存储器）的超图应用加速器，该加速器展示了高性能。

2. **An Efficient GCNs Accelerator Using 3D-Stacked Processing-in-Memory Architectures**
   - 作者：R. Wang, A. Hu, L. Zheng, Q. Wang, J. Yuan, H. Liu, L. Yu, X. Liao, and H. Jin
   - 类别：Emerging Technologies and Applications
   - 摘要：本文研究了一种高效的图卷积网络（GCNs）加速器，它采用3D堆叠的处理内存（PIM）架构。

3. **Dynamic Supply Noise Aware Timing Analysis With JIT Machine Learning Integration**
   - 作者：Y. Chen, Z. Guo, R. Wang, R. Huang, Y. Lin, and C. Zhuo
   - 类别：Modeling and Simulation
   - 摘要：虽然这篇论文的标题未直接提及“硬件加速”，但其内容涉及通过即时（JIT）机器学习集成来优化动态电源噪声感知的时序分析，这可能与硬件设计和加速有关。

4. **NicePIM: Design Space Exploration for Processing-In-Memory DNN Accelerators With 3-D Stacked-DRAM**
   - 作者：J. Wang, M. Ge, B. Ding, Q. Xu, S. Chen, and Y. Kang
   - 类别：Emerging Technologies and Applications
   - 摘要：本文介绍了NicePIM，一个用于在3D堆叠DRAM中处理内存深度神经网络（DNN）加速器的设计空间探索框架。

5. **General Purpose Deep Learning Accelerator Based on Bit Interleaving**
   - 作者：L. Chang, H. Lu, C. Li, X. Zhao, Z. Hu, J. Zhou, and X. Li
   - 类别：未明确标注，但根据标题和内容可推断为硬件加速相关
   - 摘要：提出了一种基于位交织的通用深度学习加速器，旨在提高深度学习模型的执行效率。

6. **A Distributed and Parallel Accelerator Design for 3-D Acoustic Imaging on FPGA-Based Systems**
   - 作者：D. Zhao, W. Mao, P. Chen, Y. Hu, H. Liang, Y. Dang, R. Liang, and X. Guo
   - 类别：FPGAs and Reconfigurable Systems
   - 摘要：研究了在FPGA系统上实现的用于3D声学成像的分布式并行加速器设计。

7. **Hierarchical Mapping of Large-Scale Spiking Convolutional Neural Networks Onto Resource-Constrained Neuromorphic Processor**
   - 作者：C. Xiao, X. He, Z. Yan, X. Xiao, Y. Wang, R. Gong, J. Tie, L. Wang, and W. Xu
   - 类别：未明确标注，但内容与硬件加速和神经网络映射有关
   - 摘要：讨论了将大规模脉冲卷积神经网络映射到资源受限的神经形态处理器上的分层方法。



